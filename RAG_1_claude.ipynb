{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFSc2mHhBqzc3hZOodsZL+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sg3451/Colab_Notebooks/blob/main/RAG_1_claude.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gQmEWahwzZs"
      },
      "outputs": [],
      "source": [
        "#this code is copied from that generated by Claude Sonnet 3.5\n",
        "#the purpose of this code is to use RAG to query LLMs\n",
        "#this code chunk is to set up the environment\n",
        "python -m venv rag_env\n",
        "source rag_env/bin/activate  # On Windows, use `rag_env\\Scripts\\activate`\n",
        "pip install pypdf sentence-transformers faiss-cpu anthropic flask"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use this system:\n",
        "\n",
        "1. Set up your local directories for PDFs, embeddings, and the FAISS index.\n",
        "2. Run the rag_pipeline function once to process documents, generate embeddings, and create the index.\n",
        "3. On subsequent runs, it will load the pre-computed embeddings and index, making queries faster."
      ],
      "metadata": {
        "id": "_Fbbc8mp0CGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Document processing :create a script to extract text from my PDF documents\n",
        "import os\n",
        "   from pypdf import PdfReader\n",
        "\n",
        "   def extract_text_from_pdf(pdf_path):\n",
        "       reader = PdfReader(pdf_path)\n",
        "       text = \"\"\n",
        "       for page in reader.pages:\n",
        "           text += page.extract_text() + \"\\n\"\n",
        "       return text\n",
        "\n",
        "   def process_documents(directory):\n",
        "       documents = []\n",
        "       for filename in os.listdir(directory):\n",
        "           if filename.endswith(\".pdf\"):\n",
        "               file_path = os.path.join(directory, filename)\n",
        "               text = extract_text_from_pdf(file_path)\n",
        "               documents.append({\"filename\": filename, \"text\": text})\n",
        "       return documents\n",
        "\n",
        "   # Usage\n",
        "   pdf_directory = \"path/to/your/pdfs\" #specify the path to folder where the pdfs are stored\n",
        "   processed_docs = process_documents(pdf_directory)"
      ],
      "metadata": {
        "id": "ihxDa8WfxQSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Text embedding : Create a function to embed the extracted text using sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "   def embed_documents(documents, model_name='all-MiniLM-L6-v2'): #model name can be changed\n",
        "       model = SentenceTransformer(model_name)\n",
        "       embeddings = []\n",
        "       for doc in documents:\n",
        "           embedding = model.encode(doc['text'])\n",
        "           embeddings.append(embedding)\n",
        "       return embeddings\n",
        "\n",
        "   # Usage\n",
        "   embeddings = embed_documents(processed_docs)"
      ],
      "metadata": {
        "id": "Bk9eoSvjxhEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The embeddings are generated and stored in memory in the current implementation. To persist them locally, we can add a function to save and load embeddings\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def save_embeddings(embeddings, directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    for i, embedding in enumerate(embeddings):\n",
        "        np.save(os.path.join(directory, f\"embedding_{i}.npy\"), embedding)\n",
        "\n",
        "def load_embeddings(directory):\n",
        "    embeddings = []\n",
        "    for filename in sorted(os.listdir(directory)):\n",
        "        if filename.endswith(\".npy\"):\n",
        "            embedding = np.load(os.path.join(directory, filename))\n",
        "            embeddings.append(embedding)\n",
        "    return embeddings\n",
        "\n",
        "# Usage\n",
        "embeddings_directory = \"path/to/local/embeddings\"\n",
        "save_embeddings(embeddings, embeddings_directory)\n",
        "loaded_embeddings = load_embeddings(embeddings_directory)"
      ],
      "metadata": {
        "id": "dA7eSJWzzWMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Vector Database:Use FAISS to create and search a vector database\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "def create_faiss_index(embeddings):\n",
        "    dimension = len(embeddings[0])\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "    index.add(np.array(embeddings).astype('float32'))\n",
        "    return index\n",
        "\n",
        "def search_similar_documents(index, query_embedding, k=5):\n",
        "    distances, indices = index.search(np.array([query_embedding]).astype('float32'), k)\n",
        "    return indices[0]\n",
        "\n",
        "def save_faiss_index(index, filepath):\n",
        "    faiss.write_index(index, filepath)\n",
        "\n",
        "def load_faiss_index(filepath):\n",
        "    return faiss.read_index(filepath)\n",
        "\n",
        "# Usage\n",
        "faiss_index = create_faiss_index(embeddings)\n",
        "index_filepath = \"path/to/local/faiss_index.bin\"\n",
        "save_faiss_index(faiss_index, index_filepath)\n",
        "loaded_index = load_faiss_index(index_filepath)"
      ],
      "metadata": {
        "id": "OqpiWDG1x92R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Integration with Claude:Use the Anthropic API to interact with Claude\n",
        "from anthropic import Anthropic\n",
        "\n",
        "   anthropic = Anthropic(api_key=\"your-api-key-here\")\n",
        "\n",
        "   def query_claude(query, context):\n",
        "       prompt = f\"Context: {context}\\n\\nQuery: {query}\\n\\nResponse:\"\n",
        "       response = anthropic.completions.create(\n",
        "           model=\"claude-3-sonnet-20240229\",\n",
        "           max_tokens_to_sample=300,\n",
        "           prompt=prompt\n",
        "       )\n",
        "       return response.completion\n",
        "\n",
        "   # Usage\n",
        "   response = query_claude(\"What is the main topic?\", \"Here's some context...\")"
      ],
      "metadata": {
        "id": "LEPZ17_ryKvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Orchestration:Create a main script to tie everything together\n",
        "from document_processor import process_documents\n",
        "from text_embedder import embed_documents\n",
        "from vector_database import create_faiss_index, search_similar_documents, save_faiss_index, load_faiss_index\n",
        "from local_embeddings_handler import save_embeddings, load_embeddings\n",
        "from claude_integration import query_claude\n",
        "import os\n",
        "\n",
        "def rag_pipeline(query, pdf_directory, embeddings_directory, index_filepath):\n",
        "    # Process documents if not already processed\n",
        "    if not os.path.exists(embeddings_directory):\n",
        "        documents = process_documents(pdf_directory)\n",
        "        embeddings = embed_documents(documents)\n",
        "        save_embeddings(embeddings, embeddings_directory)\n",
        "        faiss_index = create_faiss_index(embeddings)\n",
        "        save_faiss_index(faiss_index, index_filepath)\n",
        "    else:\n",
        "        documents = process_documents(pdf_directory)  # We still need to process documents for text retrieval\n",
        "        embeddings = load_embeddings(embeddings_directory)\n",
        "        faiss_index = load_faiss_index(index_filepath)\n",
        "\n",
        "    # Embed the query\n",
        "    query_embedding = embed_documents([{'text': query}])[0]\n",
        "\n",
        "    # Find similar documents\n",
        "    similar_doc_indices = search_similar_documents(faiss_index, query_embedding)\n",
        "\n",
        "    # Prepare context\n",
        "    context = \"\\n\".join([documents[i]['text'] for i in similar_doc_indices])\n",
        "\n",
        "    # Query Claude\n",
        "    response = query_claude(query, context)\n",
        "\n",
        "    return response\n",
        "\n",
        "# Usage\n",
        "pdf_directory = \"path/to/your/pdfs\"\n",
        "embeddings_directory = \"path/to/local/embeddings\"\n",
        "index_filepath = \"path/to/local/faiss_index.bin\"\n",
        "query = \"What is the main topic discussed in these documents?\"\n",
        "result = rag_pipeline(query, pdf_directory, embeddings_directory, index_filepath)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "8P7WVtM_yRVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#User Interface:Create a simple Flask web application for user interaction\n",
        "from flask import Flask, render_template, request\n",
        "   from rag_orchestrator import rag_pipeline\n",
        "\n",
        "   app = Flask(__name__)\n",
        "\n",
        "   @app.route('/', methods=['GET', 'POST'])\n",
        "   def index():\n",
        "       if request.method == 'POST':\n",
        "           query = request.form['query']\n",
        "           pdf_directory = \"path/to/your/pdfs\"\n",
        "           result = rag_pipeline(query, pdf_directory)\n",
        "           return render_template('index.html', result=result)\n",
        "       return render_template('index.html')\n",
        "\n",
        "   if __name__ == '__main__':\n",
        "       app.run(debug=True)"
      ],
      "metadata": {
        "id": "228t373Iyaz8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9bEUhtMN4e9",
        "outputId": "9c48d2ba-d3d1-4773-eea4-29b196334be5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Collecting anthropic\n",
            "  Downloading anthropic-0.31.2-py3-none-any.whl (865 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.5/865.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.7.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from anthropic)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jiter<1,>=0.4.0 (from anthropic)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->anthropic)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->anthropic)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.20.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.4)\n",
            "Installing collected packages: jiter, h11, httpcore, httpx, anthropic\n",
            "Successfully installed anthropic-0.31.2 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install requests beautifulsoup4 anthropic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import anthropic"
      ],
      "metadata": {
        "id": "nQiEvU_eOVcA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#input anthropic key\n",
        "ANTHROPIC_API_KEY = \"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\""
      ],
      "metadata": {
        "id": "9cAyife9Oa8g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_newsletter_content(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    content = soup.find('body').get_text()\n",
        "    return content"
      ],
      "metadata": {
        "id": "MZS5moxFPHK1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(content):\n",
        "    anthropic_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY) # Use anthropic_client instead of anthropic\n",
        "\n",
        "    #Define the prompt strings\n",
        "    HUMAN_PROMPT = \"Human: \"\n",
        "    AI_PROMPT = \"Assistant: \"\n",
        "\n",
        "    prompt = f\"{HUMAN_PROMPT} You are an expert content summarizer. Summarize the text enclosed within triple quotes below. Keep the summary to less than 100 words. The style of the summary should be for the layman. There should be no bullet points or numbered list. All of the summary should be in plain text, fitting in one paragraph:\\n\\n{content}\\n\\nSummary:{AI_PROMPT}\"\n",
        "\n",
        "    response = anthropic_client.completions.create( # Use anthropic_client\n",
        "        model=\"claude-instant-v1\",\n",
        "        max_tokens_to_sample=300,\n",
        "        prompt=prompt,\n",
        "        temperature=0.5,\n",
        "    )\n",
        "\n",
        "    return response.completion"
      ],
      "metadata": {
        "id": "E7uonuP3RNdw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    url = input(\"Enter the URL of the AI newsletter: \")\n",
        "    content = fetch_newsletter_content(url)\n",
        "    summary = generate_summary(content)\n",
        "    print(\"\\nSummary:\")\n",
        "    print(summary)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "jHBkV3qXTo6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0dd282e-bf77-45ee-c0eb-1f22f922169d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the URL of the AI newsletter: https://a.tldrnewsletter.com/web-version?ep=1&lc=234614ea-6cea-11ee-a5ff-f57b4ac037c3&p=a4812396-442c-11ef-bc74-8f14d84a8f1f&pt=campaign&t=1721221794&s=8f2eb27f13688324409bc8b3fdb62fb11add0ed40559e1c8f88810b3f67a56da\n",
            "\n",
            "Summary:\n",
            " Here is a 97-word summary in one paragraph:\n",
            "\n",
            "Whistleblowers have accused OpenAI of illegally restrictive practices in its employment agreements. According to a letter to the SEC, the whistleblowers allege that OpenAI's severance, non-disparagement, and non-disclosure agreements violate employees' rights to whistleblower incentives and compensation by placing undue restrictions on their communication with government regulators. The letter urges the SEC to investigate OpenAI's employment agreements for potentially violating employees' legal protections.\n"
          ]
        }
      ]
    }
  ]
}